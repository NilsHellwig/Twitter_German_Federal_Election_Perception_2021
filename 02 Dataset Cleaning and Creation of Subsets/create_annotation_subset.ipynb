{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a2d3d2-6f3a-4f9e-987f-636acb8d2583",
   "metadata": {},
   "source": [
    "# Notebook: Create Subset\n",
    "\n",
    "This notebook is used to create a subset of **2000** tweets, which will then be annotated with respect to their sentiment.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06150cb8-bd07-413c-817a-d346f10b32ac",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab58f7b-ae84-4dc0-a521-6215096f0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988733c0-13c0-4318-bf57-dabf11fbf4a4",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692d6040-8acc-4cc1-99b9-b14523639391",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_DATASET_PATH = '../Datasets/annotation_dataset'\n",
    "DATASET_PATH = '../Datasets/dataset/'\n",
    "SUBSET_SIZE = 2000\n",
    "SEED_VALUE = 0\n",
    "PARTIES = [\"CDU_CSU\", \"SPD\", \"AFD\", \"FDP\", \"GRUENE\", \"LINKE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9edba-ca8f-49be-aa38-1460c13ba0f6",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacc92a-ed60-41ae-be2a-706c00759475",
   "metadata": {},
   "source": [
    "### 1. Get Reproducable Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7168c3-07d4-4403-be63-46ffcbcc5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1121b-d789-45c7-84a7-557256c2a578",
   "metadata": {},
   "source": [
    "### 2. Calculate Number of Tweets crawled for each party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8faa9305-c8a6-4ec1-9b06-18831a80e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tweets_total = 0\n",
    "party_statistics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b563bd79-5b1a-4892-9a82-7206c3f4bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in PARTIES:\n",
    "    n_tweets_party = 0\n",
    "    for subdir, _, files in os.walk(DATASET_PATH + party):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and subdir[len(DATASET_PATH):] in PARTIES:\n",
    "                # Get username of CSV file\n",
    "                username = file[:-4]\n",
    "\n",
    "                # Read dataframe\n",
    "                df = pd.read_csv(DATASET_PATH + party + \"/\" + file, sep=\",\", index_col=0)\n",
    "\n",
    "                # Add to counter\n",
    "                n_tweets_party += df.shape[0]\n",
    "\n",
    "                # Add length to n_tweets_total\n",
    "                n_tweets_total += df.shape[0]\n",
    "\n",
    "    party_statistics[party] = n_tweets_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec28b0e5-c25f-4031-a6a0-d1e7e6942ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707241"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tweets_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b4e868-847f-4d0a-b9a7-8ac9951f7f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDU_CSU': 227683,\n",
       " 'SPD': 228415,\n",
       " 'AFD': 57572,\n",
       " 'FDP': 79815,\n",
       " 'GRUENE': 73261,\n",
       " 'LINKE': 40495}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0da95a-4669-4cc7-a513-cc900017670c",
   "metadata": {},
   "source": [
    "### 3. Check which party gets an additional Tweet / if tweet needs to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5299b8-8c9b-4c5e-9770-d0fa8045dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_with_max_value_under_0_5(dictionary):\n",
    "    filtered_dict = {}\n",
    "    for key, value in dictionary.items():\n",
    "        if value < 0.5:\n",
    "            filtered_dict[key] = value\n",
    "    return max(filtered_dict, key=filtered_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4f4544-2a74-4353-893c-abdf9f22b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(x, d):\n",
    "    return int(x*(10.0**d))/(10.0**d)\n",
    "\n",
    "for party in party_statistics:\n",
    "    party_statistics[party] = ((SUBSET_SIZE / n_tweets_total) * party_statistics[party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f951303e-4f6f-4ee2-8c0d-e84d700cf2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDU_CSU': 643.8625588731422,\n",
       " 'SPD': 645.932574610352,\n",
       " 'AFD': 162.8073033096215,\n",
       " 'FDP': 225.70806839535604,\n",
       " 'GRUENE': 207.1740750324147,\n",
       " 'LINKE': 114.51541977911349}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995571ba-50b8-4e24-a334-a9de6cbfa2f3",
   "metadata": {},
   "source": [
    "### 4. Get Random Tweets From Each Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e758de-ed07-4c45-840f-c2cbb7d34d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subset_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec46c1-3884-4b30-b8b3-3e79e8e6e3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotation_dataset = pd.DataFrame()\n",
    "for party in PARTIES:\n",
    "    # Initialize an empty DataFrame to store the tweets from accounts of a party\n",
    "    df_party = pd.DataFrame()\n",
    "\n",
    "    for subdir, _, files in os.walk(DATASET_PATH + party):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and subdir[len(DATASET_PATH):] in PARTIES:\n",
    "                # Get username of CSV file\n",
    "                username = file[:-4]\n",
    "\n",
    "                # Read dataframe\n",
    "                df_account = pd.read_csv(DATASET_PATH + party + \"/\" + file, sep=\",\", index_col=0)\n",
    "\n",
    "                # Add dataframe to party dataframe\n",
    "                df_party = pd.concat([df_party, df_account], axis=0).reset_index().drop(columns='index')\n",
    "\n",
    "    n_tweets_party = df_party.shape[0]\n",
    "    n_tweets_party_for_subset = round((SUBSET_SIZE / n_tweets_total) * n_tweets_party)\n",
    "\n",
    "    n_subset_total += n_tweets_party_for_subset\n",
    "\n",
    "    df_samples_for_party = df_party.sample(n=n_tweets_party_for_subset, random_state=SEED_VALUE)\n",
    "    annotation_dataset = pd.concat([annotation_dataset, df_samples_for_party], axis=0).reset_index().drop(columns='index')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010af5b-e7a3-4854-944e-9c6250cae815",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subset_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8918727-e308-4751-b2db-21c73fc52190",
   "metadata": {},
   "source": [
    "### 4. Create Sub Datasets for Annotation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd2fc8-14a6-421e-b2ec-6cb818a9fbc8",
   "metadata": {},
   "source": [
    "Save dataset for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41e566-7407-4496-9a15-97979b3bdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(ANNOTATION_DATASET_PATH)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da96cf-d110-4bb0-b214-267ad7e2afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataset = annotation_dataset.sample(frac=1, random_state=SEED_VALUE).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631640bf-d308-451c-a890-6701daaa23bd",
   "metadata": {},
   "source": [
    "By rounding the number of tweets, it is possible that not exactly 2000 tweets will come out. In this case, one tweet must be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1cf01-b4f6-4057-bba3-ae01f5254aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_to_exclude_tweets = annotation_dataset[annotation_dataset['source_party'] == 'LINKE']\n",
    "tweet_to_delete = party_to_exclude_tweets.sample(n=1)\n",
    "annotation_dataset = annotation_dataset.drop(tweet_to_delete.index).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714f856-d468-49aa-b3e3-f319667dca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataset['source_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29804a6c-dbb7-4214-a559-e701d4313801",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4a885-bdd6-4295-a30a-e5f6a71e66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf807bc-3b36-4fe4-9c03-7c7ebb553f47",
   "metadata": {},
   "source": [
    "Save entire annotation_dataset (unlabled) as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62e4ce-502b-40f7-97e9-ecb18efa5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataset.to_csv(ANNOTATION_DATASET_PATH + \"/annotation_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05e7c6-7445-4b53-ae53-2dc93ad150c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataset['source_party'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c15743-2414-4428-9bc1-58a3aec7c3af",
   "metadata": {},
   "source": [
    "For the whole corpus, we do not delete duplicates. Duplicates can occur because a tweet can mention several politicians at once, which means that a tweet could be crawled for multiple politicians. However, we want to avoid evaluating the trained BERT model with tweets that were also used for training. Therefore, we make sure that there are no duplicates among the 2000 annotated tweets that we will later use for training and evaluation of our BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fbed2-a46d-4ddd-89f6-2dc43e82229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the 'id' column is unique\n",
    "is_unique = df['id'].is_unique\n",
    "print(\"Dataset uniqueness: \", is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e867a01-ad8c-4669-9222-3b49e6731be5",
   "metadata": {},
   "source": [
    "Add column for sentiment label and columns with information that might be helpfull for annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c466c1-b8df-42e0-a70c-8c14e4a613ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataset[\"sentiment\"] = \"\"\n",
    "annotation_dataset = annotation_dataset.loc[:, ['id', 'username', 'date', 'sentiment', 'tweet', 'link', 'source_account', 'source_party']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ced74-cd82-46b0-940a-59128bfd88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session1 = annotation_dataset[:int(SUBSET_SIZE/2)]\n",
    "df_session2 = annotation_dataset[int(SUBSET_SIZE/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e4ee8-0ebe-4f2d-8870-bd193cddc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session1.to_csv(ANNOTATION_DATASET_PATH + \"/tweets_session_1.csv\")\n",
    "df_session1.to_excel(ANNOTATION_DATASET_PATH + \"/tweets_session_1.xlsx\")\n",
    "df_session1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eaf39f-dc80-49eb-b452-b0c53cd2f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session2.to_csv(ANNOTATION_DATASET_PATH + \"/tweets_session_2.csv\")\n",
    "df_session2.to_excel(ANNOTATION_DATASET_PATH + \"/tweets_session_2.xlsx\")\n",
    "df_session2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2db3b2-546a-4130-afd8-c33a5bc04759",
   "metadata": {},
   "source": [
    "## IMPORTANT: NEXT STEPS\n",
    "\n",
    "1. Create new Folder \"annotated_datasets\" in `/Datasets`\n",
    "2. Add Annotated Datasets in .xlsx format \n",
    "3. Name these:\n",
    "`\n",
    "['../Datasets/annotated_dataset/tweets_session_1_1.xlsx',\n",
    " '../Datasets/annotated_dataset/tweets_session_1_2.xlsx',\n",
    " '../Datasets/annotated_dataset/tweets_session_1_3.xlsx',\n",
    " '../Datasets/annotated_dataset/tweets_session_2_1.xlsx',\n",
    " '../Datasets/annotated_dataset/tweets_session_2_2.xlsx',\n",
    " '../Datasets/annotated_dataset/tweets_session_2_3.xlsx']\n",
    "`\n",
    "\n",
    "Schema:\n",
    "\n",
    "`\n",
    "../Datasets/annotated_dataset/tweets_session_{SESSION_ID}_{ANNOTATOR_ID}.xlsx'\n",
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
