{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d027f1b",
   "metadata": {},
   "source": [
    "# Notebook: Calculate Agreement\n",
    "\n",
    "This notebook is used to calculate the inter-rater agreement using Krippendorf's Alpha.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce848e0",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3ab732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import inter_rater as irr\n",
    "import krippendorff as kd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15548d80",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb929ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_DATASET_PATH = \"../Datasets/annotated_dataset/\"\n",
    "LABEL_CODING = {'NEUTRAL': 3, 'NEGATIVE': 2, 'POSITIVE': 1, 'MIXED': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4be97f",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad729756",
   "metadata": {},
   "source": [
    "### 1. Load Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f88d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = sorted(glob.glob(ANNOTATED_DATASET_PATH + \"*.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1836feab-ff90-497a-807d-c20432ba5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and concatenate annotator 1's session 1 and 2 data\n",
    "df_annotator_1 = pd.concat([\n",
    "    pd.read_excel(ANNOTATED_DATASET_PATH + \"tweets_session_1_1.xlsx\"),\n",
    "    pd.read_excel(ANNOTATED_DATASET_PATH + \"tweets_session_2_1.xlsx\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab65195c-acd6-4f5f-98b4-3172993ab856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename sentiment column and recode labels\n",
    "df_annotator_1.rename(columns={'sentiment': 'sentiment_1'}, inplace=True)\n",
    "df_annotator_1['sentiment_1'] = df_annotator_1['sentiment_1'].map(LABEL_CODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd14790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and concatenate annotator 2's session 1 and 2 data\n",
    "df_annotator_2 = pd.concat([\n",
    "    pd.read_excel(ANNOTATED_DATASET_PATH + \"tweets_session_1_2.xlsx\"),\n",
    "    pd.read_excel(ANNOTATED_DATASET_PATH + \"tweets_session_2_2.xlsx\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ac9588-f0aa-43e2-a59c-745e33457cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename sentiment column and recode labels\n",
    "df_annotator_2.rename(columns={'sentiment': 'sentiment_2'}, inplace=True)\n",
    "df_annotator_2['sentiment_2'] = df_annotator_2['sentiment_2'].map(LABEL_CODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c46dd84-74b7-47da-bf57-f6869d7bb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate annotator 1 and 2 data\n",
    "df_all_annotations = pd.concat([\n",
    "    df_annotator_1[['sentiment_1']], \n",
    "    df_annotator_2[['sentiment_2']]\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8956abc1-c7d4-435b-aeb6-30286b58d13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>sentiment_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment_1, sentiment_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values in sentiment columns\n",
    "print(df_all_annotations[df_all_annotations['sentiment_1'].isnull()])\n",
    "print(df_all_annotations[df_all_annotations['sentiment_2'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df9b6c5-9b0b-41b6-bf58-0f16ecd8ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_annotations = df_all_annotations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ff4f0eb-ef93-45f8-9f90-c193954c4821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_values = len(df_all_annotations[df_all_annotations['sentiment_1'] == df_all_annotations['sentiment_2']])\n",
    "equal_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41132cdc",
   "metadata": {},
   "source": [
    "### 2. Calculate Krippendorff's Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "febaaee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266937120270791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows are the coders (annotators) # of coders\n",
    "# Columns are the individual items (sentiment of tweet) # of tweets\n",
    "value_counts = df_all_annotations.loc[:, df_all_annotations.columns != 'id']\n",
    "value_counts = value_counts.to_numpy().transpose()\n",
    "kd.alpha(reliability_data=value_counts, level_of_measurement=\"nominal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0235845",
   "metadata": {},
   "source": [
    "### 3. Calculate Fleiss' Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "269337c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = irr.aggregate_raters(df_all_annotations.loc[:, df_all_annotations.columns != 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd3bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266253683691716"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irr.fleiss_kappa(agg[0], method='fleiss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
