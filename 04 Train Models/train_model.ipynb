{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029abeac-4e2c-4d5f-8daf-795d5b78b245",
   "metadata": {},
   "source": [
    "# Notebook: Train Model\n",
    "\n",
    "This notebook is used to train a classification model given a dataset of tweets. Results of the training are saved in CSV and JSON.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf5bc3-0afa-4583-84a5-b970a691d42c",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a2c4500d-fd29-4d68-ac75-1ff84c8f5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from get_germeval_2017_dataset import get_germeval_2017_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30e67d-c7a8-4c0d-b5c2-0cc72df424a8",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "20a5a837-0abe-49ab-9c24-3e0e8f8cd504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "SPLIT_ID = 0\n",
    "TEST_DATASET_PATH = f'../Datasets/k_fold_splits/TRAIN_TEST_{SPLIT_ID}/test.csv'\n",
    "MODEL_NAME = f'GermEval_and_Annotaded_it_{SPLIT_ID}'\n",
    "MODEL_DIRECTORY_PATH = f'../Trainings/Models/' + MODEL_NAME\n",
    "PATH_RESULT_DATA = f'../Trainings/Results/' + MODEL_NAME\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "N_TRAIN_EPOCHS = 4\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "USE_CUDA = False\n",
    "\n",
    "# OTHER MODEL SETTINGS\n",
    "SAVE_MODEL = True\n",
    "N_LABELS = 3\n",
    "EVALUATE_MODEL = True\n",
    "SEED_VALUE = 0\n",
    "LABEL_DEFINITION = {'negative': 1, 'positive': 0, 'neutral': 2}\n",
    "\n",
    "## MODEL TYPE\n",
    "MODEL_TYPE = \"bert\"\n",
    "MODEL_NAME = \"deepset/gbert-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7383c58-6d48-4708-8379-394d66011e58",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66018039-82cd-4539-b734-d09daf2c82e6",
   "metadata": {},
   "source": [
    "### 1. Get Reproducable Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3f3e5faa-0c46-4860-9093-0b0dcb038ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c9a68-c98f-42f8-b74a-ff2b69c3b117",
   "metadata": {},
   "source": [
    "### 2. Load Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc7d49-fc22-43f2-abb9-ce7c7a71a073",
   "metadata": {},
   "source": [
    "#### Load Training Data\n",
    "**Important:** Comment out unnecessary data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f40d4b85-2e42-4084-9f7c-52d415883dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_annotated_split = pd.read_csv(f'../Datasets/k_fold_splits/TRAIN_TEST_{SPLIT_ID}/train.csv', encoding=\"utf-8\")[[\"tweet\",\"sentiment\"]].rename(columns={\"tweet\":\"text\"})\n",
    "train_df_germeval = get_germeval_2017_dataset()\n",
    "train_df_annotated_total = pd.read_csv(\"../Datasets/annotations_matched_filtered.csv\", encoding=\"utf-8\")[[\"tweet\",\"sentiment\"]].rename(columns={\"tweet\":\"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "59f8e92d-a309-4b77-8e20-4e9917aaaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df_annotated_split, train_df_germeval], axis=0).sample(frac=1, random_state=SEED_VALUE).reset_index(drop=True)\n",
    "train_df['sentiment'] = train_df['sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc09df-1410-4a5a-8d61-435f66773fa5",
   "metadata": {},
   "source": [
    "Check Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e8ff5-eee6-4fdb-aeb5-270f04d4edb9",
   "metadata": {},
   "source": [
    "#### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a82fd1a-ee55-44bf-a8fe-7ab5086292ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    test_df = pd.read_csv(TEST_DATASET_PATH, encoding=\"utf-8\")[[\"tweet\",\"sentiment\"]].rename(columns={\"tweet\":\"text\"})\n",
    "    test_df['sentiment'] = test_df['sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c825411-125b-4f46-b944-e4c21b319a8b",
   "metadata": {},
   "source": [
    "#### Replace label strings with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f19afe51-7b1e-4052-8640-2c5818221937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentiment'] = train_df['sentiment'].replace(LABEL_DEFINITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ea5c123-9d0b-4db0-92a9-a6e79dfde884",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    test_df['sentiment'] = test_df['sentiment'].replace(LABEL_DEFINITION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c2e7e-d6e4-42cf-9ddd-c8a860d0c7e0",
   "metadata": {},
   "source": [
    "### 3. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f771fd1-d08d-4f2c-974d-dd162bf098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"fp16\":False,\n",
    "    \"num_train_epochs\":N_TRAIN_EPOCHS,\n",
    "    \"overwrite_output_dir\":True,\n",
    "    \"train_batch_size\":TRAIN_BATCH_SIZE,\n",
    "    \"eval_batch_size\":TEST_BATCH_SIZE,\n",
    "    \"manual_seed\": SEED_VALUE,\n",
    "    \"reprocess_input_data\":True,\n",
    "    \"no_save\":True,\n",
    "    \"no_cache\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5b84f368-ca2c-45f2-b3e1-624842e30755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(model_type=MODEL_TYPE, model_name=MODEL_NAME, num_labels=N_LABELS, args=training_args, use_cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d0c66-f492-4fad-bebe-a8b3f31679e9",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7c58ec18-1a76-40b7-a952-82716c4cd853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:612: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9bf46ccd7644adbc7c58984c730d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type int64 without overflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:619\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         train_examples \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    616\u001b[0m             train_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    617\u001b[0m             train_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    618\u001b[0m         )\n\u001b[0;32m--> 619\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_cache_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m train_sampler \u001b[38;5;241m=\u001b[39m RandomSampler(train_dataset)\n\u001b[1;32m    623\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m    624\u001b[0m     train_dataset,\n\u001b[1;32m    625\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[1;32m    626\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[1;32m    627\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1827\u001b[0m, in \u001b[0;36mClassificationModel.load_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1827\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/simpletransformers/classification/classification_utils.py:282\u001b[0m, in \u001b[0;36mClassificationDataset.__init__\u001b[0;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, tokenizer, args, mode, multi_label, output_mode, no_cache):\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_classification_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_cache\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/simpletransformers/classification/classification_utils.py:267\u001b[0m, in \u001b[0;36mbuild_classification_dataset\u001b[0;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    262\u001b[0m     examples \u001b[38;5;241m=\u001b[39m preprocess_data(\n\u001b[1;32m    263\u001b[0m         text_a, text_b, labels, tokenizer, args\u001b[38;5;241m.\u001b[39mmax_seq_length\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 267\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    269\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type int64 without overflow"
     ]
    }
   ],
   "source": [
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba82ab-2980-49eb-a236-1e27150d3add",
   "metadata": {},
   "source": [
    "### 5. Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68ca34-d469-4863-9f0c-6ce2bffc8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = accuracy_score\n",
    "\n",
    "def f1_metrics(labels, predictions):\n",
    "    metrics = {\n",
    "      \"f1_macro\": f1_score(labels, predictions, average='macro'),\n",
    "      \"f1_micro\": f1_score(labels, predictions, average='micro'),\n",
    "      \"f1_weighted\": f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def precision_metrics(labels, predictions):\n",
    "    metrics = {\n",
    "      \"precision_macro\": precision_score(labels, predictions, average='macro'),\n",
    "      \"precision_micro\": precision_score(labels, predictions, average='micro'),\n",
    "      \"precision_weighted\": precision_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def recall_metrics(labels, predictions):\n",
    "    metrics = {\n",
    "      \"recall_macro\": recall_score(labels, predictions, average='macro'),\n",
    "      \"recall_micro\": recall_score(labels, predictions, average='micro'),\n",
    "      \"recall_weighted\": recall_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a5715-fc3c-40cb-b802-4ba0db25e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_each_class(labels, predictions):\n",
    "    precision_recall = {}\n",
    "    for c in set(labels):\n",
    "        label_idx = [i for i, x in enumerate(labels) if x == c]\n",
    "        pred_idx = [i for i, x in enumerate(predictions) if x == c]\n",
    "        precision = len(set(label_idx).intersection(set(pred_idx))) / len(pred_idx) if len(pred_idx) > 0 else 0\n",
    "        recall = len(set(label_idx).intersection(set(pred_idx))) / len(label_idx) if len(label_idx) > 0 else 0\n",
    "        precision_recall[c] = {\"precision\": precision, \"recall\": recall}\n",
    "    return {\"precision_recall_each_class\": precision_recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff215709-acfa-42bb-88cc-3ef8edc44675",
   "metadata": {},
   "source": [
    "### 6. Create Directories for Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497dbc9-6219-4c75-9c86-28744a0a9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"../Trainings\")\n",
    "except FileExistsError:\n",
    "    # The directory already exists, so do nothing\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"../Trainings/Results\")\n",
    "except FileExistsError:\n",
    "    # The directory already exists, so do nothing\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"../Trainings/Models\")\n",
    "except FileExistsError:\n",
    "    # The directory already exists, so do nothing\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884505d2-9d3a-407b-bd18-5fcaa3e6c1d5",
   "metadata": {},
   "source": [
    "### 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b63e51-ab2a-46fb-9ddb-522b7b5d31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=accuracy_metric, f1=f1_metrics, precision=precision_metrics, recall=recall_metrics, precision_recall_each_class=precision_recall_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3422176-0aa6-4cd8-bf64-426d387a728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    with open(PATH_RESULT_DATA+\".json\", 'w') as f:\n",
    "        json.dump(result, f, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c93b7-1dbc-4348-8c35-b40f47bf71be",
   "metadata": {},
   "source": [
    "### 8. Save Evaluated Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3485a-adfd-4784-b7e6-e5889af1f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df\n",
    "texts = []\n",
    "for index, row in test_data.iterrows():\n",
    "    texts.append(row[\"text\"])\n",
    "predictions, raw_outputs = model.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb4442-5dec-4b81-9487-1cb52b794977",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_out = test_df.assign(pred=pd.Series(predictions))\n",
    "test_df_out.to_csv(PATH_RESULT_DATA+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e5b55-1229-4406-acae-c985af7d1814",
   "metadata": {},
   "source": [
    "### 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0d2c9-6750-454d-a3e1-cb8cbdc827a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_MODEL:\n",
    "    model.save_model(MODEL_DIRECTORY_PATH, MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
