{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029abeac-4e2c-4d5f-8daf-795d5b78b245",
   "metadata": {},
   "source": [
    "# Notebook: Train Model\n",
    "\n",
    "This notebook is used to train a classification model given a dataset of tweets. Results of the training are saved in CSV and JSON.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf5bc3-0afa-4583-84a5-b970a691d42c",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c4500d-fd29-4d68-ac75-1ff84c8f5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from get_germeval_2017_dataset import get_germeval_2017_dataset\n",
    "from get_schmidt_2022_dataset import get_schmidt_2022_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30e67d-c7a8-4c0d-b5c2-0cc72df424a8",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a5a837-0abe-49ab-9c24-3e0e8f8cd504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "SPLIT_ID = 0\n",
    "TEST_DATASET_PATH = f'../Datasets/k_fold_splits/TRAIN_TEST_{SPLIT_ID}/test.csv'\n",
    "MODEL_NAME = f'BERT-4_{SPLIT_ID}'\n",
    "MODEL_DIRECTORY_PATH = f'../Trainings/Models/' + MODEL_NAME\n",
    "PATH_RESULT_DATA = f'../Trainings/Results/' + MODEL_NAME\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "N_TRAIN_EPOCHS = 4\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "USE_CUDA = True\n",
    "\n",
    "# OTHER MODEL SETTINGS\n",
    "SAVE_MODEL = False\n",
    "N_LABELS = 3\n",
    "EVALUATE_MODEL = True\n",
    "SEED_VALUE = 0\n",
    "LABEL_DEFINITION = {'negative': 1, 'positive': 0, 'neutral': 2}\n",
    "\n",
    "## MODEL TYPE\n",
    "MODEL_TYPE = \"bert\"\n",
    "MODEL_NAME = \"deepset/gbert-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7383c58-6d48-4708-8379-394d66011e58",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66018039-82cd-4539-b734-d09daf2c82e6",
   "metadata": {},
   "source": [
    "### 1. Get Reproducable Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3e5faa-0c46-4860-9093-0b0dcb038ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c9a68-c98f-42f8-b74a-ff2b69c3b117",
   "metadata": {},
   "source": [
    "### 2. Load Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc7d49-fc22-43f2-abb9-ce7c7a71a073",
   "metadata": {},
   "source": [
    "#### Load Training Data\n",
    "**Important:** Comment out unnecessary data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40d4b85-2e42-4084-9f7c-52d415883dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_annotated_split = pd.read_csv(f'../Datasets/k_fold_splits/TRAIN_TEST_{SPLIT_ID}/train.csv', encoding=\"utf-8\")[[\"tweet\",\"sentiment\"]].rename(columns={\"tweet\":\"text\"})\n",
    "train_df_germeval = get_germeval_2017_dataset()\n",
    "train_df_schmidt = get_schmidt_2022_dataset()\n",
    "train_df_annotated_total = pd.read_csv(\"../Datasets/annotations_matched_filtered.csv\", encoding=\"utf-8\")[[\"tweet\",\"sentiment\"]].rename(columns={\"tweet\":\"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f8e92d-a309-4b77-8e20-4e9917aaaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df_annotated_split, train_df_germeval, train_df_schmidt], axis=0).sample(frac=1, random_state=SEED_VALUE).reset_index(drop=True)\n",
    "train_df['sentiment'] = train_df['sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e8ff5-eee6-4fdb-aeb5-270f04d4edb9",
   "metadata": {},
   "source": [
    "#### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a82fd1a-ee55-44bf-a8fe-7ab5086292ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    test_df = pd.read_csv(TEST_DATASET_PATH, encoding=\"utf-8\")[[\"tweet\",\"sentiment\"]].rename(columns={\"tweet\":\"text\"})\n",
    "    test_df['sentiment'] = test_df['sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c825411-125b-4f46-b944-e4c21b319a8b",
   "metadata": {},
   "source": [
    "#### Replace label strings with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19afe51-7b1e-4052-8640-2c5818221937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentiment'] = train_df['sentiment'].replace(LABEL_DEFINITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea5c123-9d0b-4db0-92a9-a6e79dfde884",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    test_df['sentiment'] = test_df['sentiment'].replace(LABEL_DEFINITION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c2e7e-d6e4-42cf-9ddd-c8a860d0c7e0",
   "metadata": {},
   "source": [
    "### 3. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f771fd1-d08d-4f2c-974d-dd162bf098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"fp16\":False,\n",
    "    \"num_train_epochs\":N_TRAIN_EPOCHS,\n",
    "    \"overwrite_output_dir\":True,\n",
    "    \"train_batch_size\":TRAIN_BATCH_SIZE,\n",
    "    \"eval_batch_size\":TEST_BATCH_SIZE,\n",
    "    \"manual_seed\": SEED_VALUE,\n",
    "    \"reprocess_input_data\":True,\n",
    "    \"no_cache\":True,\n",
    "    \"use_multiprocessing\":False,\n",
    "    \"use_multiprocessing_for_evaluation\":False,\n",
    "    \"save_model_every_epoch\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84f368-ca2c-45f2-b3e1-624842e30755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel(model_type=MODEL_TYPE, model_name=MODEL_NAME, num_labels=N_LABELS, args=training_args, use_cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d0c66-f492-4fad-bebe-a8b3f31679e9",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58ec18-1a76-40b7-a952-82716c4cd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba82ab-2980-49eb-a236-1e27150d3add",
   "metadata": {},
   "source": [
    "### 5. Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68ca34-d469-4863-9f0c-6ce2bffc8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = accuracy_score\n",
    "\n",
    "def f1_metrics(labels, predictions):\n",
    "    metrics = {\n",
    "      \"f1_macro\": f1_score(labels, predictions, average='macro'),\n",
    "      \"f1_micro\": f1_score(labels, predictions, average='micro'),\n",
    "      \"f1_weighted\": f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def precision_metrics(labels, predictions):\n",
    "    metrics = {\n",
    "      \"precision_macro\": precision_score(labels, predictions, average='macro'),\n",
    "      \"precision_micro\": precision_score(labels, predictions, average='micro'),\n",
    "      \"precision_weighted\": precision_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def recall_metrics(labels, predictions):\n",
    "    metrics = {\n",
    "      \"recall_macro\": recall_score(labels, predictions, average='macro'),\n",
    "      \"recall_micro\": recall_score(labels, predictions, average='micro'),\n",
    "      \"recall_weighted\": recall_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a5715-fc3c-40cb-b802-4ba0db25e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_each_class(labels, predictions):\n",
    "    precision_recall = {}\n",
    "    for c in set(labels):\n",
    "        label_idx = [i for i, x in enumerate(labels) if x == c]\n",
    "        pred_idx = [i for i, x in enumerate(predictions) if x == c]\n",
    "        precision = len(set(label_idx).intersection(set(pred_idx))) / len(pred_idx) if len(pred_idx) > 0 else 0\n",
    "        recall = len(set(label_idx).intersection(set(pred_idx))) / len(label_idx) if len(label_idx) > 0 else 0\n",
    "        precision_recall[c] = {\"precision\": precision, \"recall\": recall}\n",
    "    return precision_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff215709-acfa-42bb-88cc-3ef8edc44675",
   "metadata": {},
   "source": [
    "### 6. Create Directories for Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497dbc9-6219-4c75-9c86-28744a0a9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"../Trainings\")\n",
    "except FileExistsError:\n",
    "    # The directory already exists, so do nothing\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"../Trainings/Results\")\n",
    "except FileExistsError:\n",
    "    # The directory already exists, so do nothing\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"../Trainings/Models\")\n",
    "except FileExistsError:\n",
    "    # The directory already exists, so do nothing\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884505d2-9d3a-407b-bd18-5fcaa3e6c1d5",
   "metadata": {},
   "source": [
    "### 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b63e51-ab2a-46fb-9ddb-522b7b5d31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=accuracy_metric, f1=f1_metrics, precision=precision_metrics, recall=recall_metrics, precision_recall_each_class=precision_recall_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3422176-0aa6-4cd8-bf64-426d387a728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_MODEL:\n",
    "    with open(PATH_RESULT_DATA+\".json\", 'w') as f:\n",
    "        json.dump(result, f, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c93b7-1dbc-4348-8c35-b40f47bf71be",
   "metadata": {},
   "source": [
    "### 8. Save Evaluated Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3485a-adfd-4784-b7e6-e5889af1f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df\n",
    "texts = []\n",
    "for index, row in test_data.iterrows():\n",
    "    texts.append(row[\"text\"])\n",
    "predictions, raw_outputs = model.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb4442-5dec-4b81-9487-1cb52b794977",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_out = test_df.assign(pred=pd.Series(predictions))\n",
    "test_df_out.to_csv(PATH_RESULT_DATA+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e5b55-1229-4406-acae-c985af7d1814",
   "metadata": {},
   "source": [
    "### 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0d2c9-6750-454d-a3e1-cb8cbdc827a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(dest_folder):\n",
    "    src_folder = \"outputs\"\n",
    "    for item in os.listdir(src_folder):\n",
    "        src_item = os.path.join(src_folder, item)\n",
    "        dest_item = os.path.join(dest_folder, item)\n",
    "        if os.path.isdir(src_item):\n",
    "            copy_folder_contents(src_item, dest_item)\n",
    "        else:\n",
    "            shutil.copy(src_item, dest_item)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    save_model(MODEL_DIRECTORY_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
