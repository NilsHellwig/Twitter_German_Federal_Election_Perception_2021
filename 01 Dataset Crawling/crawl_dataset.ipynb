{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfe2851-4e1f-4439-b563-ab3d3cdcfe6d",
   "metadata": {},
   "source": [
    "# Notebook: Create Twitter Dataset\n",
    "\n",
    "This notebook is used to crawl tweets mentioning the 89 relevant Twitter accounts of German politicians.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087016ed-05ff-4887-b8ca-ce6d91506a38",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b664e9-31d5-469d-99fd-ce1aa607de87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import random\n",
    "import twint\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf88f6-b7cd-4989-b099-658fe967c01f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09de32ef-c206-4ccd-9b76-29a638c73ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATASET_PATH = '../Datasets/raw_dataset/'\n",
    "SEED_VALUE = 0\n",
    "N_DAYS_PER_ACCOUNT = 2\n",
    "PARTIES = ['CDU_CSU', 'FDP', 'AFD', 'LINKE', 'SPD', 'GRUENE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8462ded0-a975-4af7-aa5e-5b81d33951db",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5c562-8aaf-4aa2-aadb-27ce6273096f",
   "metadata": {},
   "source": [
    "### 1. Get Reproducable Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4b145c-ad6b-4cd7-9772-cc62e546201c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4e085-080e-40e0-9fb5-90ee2f087f15",
   "metadata": {},
   "source": [
    "### 2. Function to get a random day in one of the 12 months in 2021 (as well as the next day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2d496-d057-4c78-8a1f-95216a5dda5b",
   "metadata": {},
   "source": [
    "Twint expects a date in the format of `%Y-%m-%d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a64f87d-f360-4920-99f2-7c7b27e8b09f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_day_and_next(month: int) -> tuple:\n",
    "    # Validate the month input\n",
    "    if not 1 <= month <= 12:\n",
    "        raise ValueError(\"Month must be an integer between 1 and 12\")\n",
    "\n",
    "    # Get the number of days in a specific month\n",
    "    num_days = calendar.monthrange(2021, month)[1]\n",
    "\n",
    "    # Get random day in the month\n",
    "    day = random.randint(1, num_days)\n",
    "\n",
    "    # Format date as a string\n",
    "    date_str = f\"2021-{month:02d}-{day:02d}\"\n",
    "\n",
    "    # Convert the date string to a datetime object\n",
    "    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    # Calculate the next day\n",
    "    next_day = date + timedelta(days=1)\n",
    "\n",
    "    # Return the date and next day as a tuple\n",
    "    return (date.strftime(\"%Y-%m-%d\"), next_day.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4486b-6067-4444-a8e0-57d308ad15d3",
   "metadata": {},
   "source": [
    "Test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9633a1-7de8-4a98-8f2d-2d87f7f3bc80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random day: 2021-04-28\n",
      "Following day: 2021-04-29\n"
     ]
    }
   ],
   "source": [
    "random_day, following_day = get_random_day_and_next(4)\n",
    "\n",
    "print(f\"Random day: {random_day}\")\n",
    "print(f\"Following day: {following_day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb5078b-c603-4bb6-a21c-aecc984577c6",
   "metadata": {},
   "source": [
    "### 3. Function to retrieve all tweets with a specific @-mention and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f14a551-6d57-4d06-8152-8f8cbcab94bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tweets_for_specific_day(query: str, since: str, until:str):\n",
    "    nest_asyncio.apply()\n",
    "    config = twint.Config()\n",
    "    \n",
    "    config.Search = query  # Set the search query\n",
    "    config.Limit = 9000000000  # Set a very large limit to retrieve all tweets for a day\n",
    "    config.Since = since  # Set the start date for the search\n",
    "    config.Until = until  # Set the end date for the search\n",
    "    config.Pandas = True  # Return the results as a Pandas DataFrame\n",
    "    config.Hide_output = True  # Suppress console output\n",
    "    \n",
    "    twint.run.Search(config)\n",
    "    return twint.storage.panda.Tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68f96f-a37e-4423-943c-1f60fe3f3ce1",
   "metadata": {},
   "source": [
    "### 4. Load Accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca581ec4-7a02-4db2-a886-476afb816445",
   "metadata": {},
   "source": [
    "#### Politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e558cd-03cc-4fad-ad0b-8de94205655e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_politicians = pd.read_csv('../Datasets/accounts_politicians.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21790d46-c7b6-4026-b771-cdda3a67f6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFD</th>\n",
       "      <th>LINKE</th>\n",
       "      <th>SPD</th>\n",
       "      <th>GRUENE</th>\n",
       "      <th>FDP</th>\n",
       "      <th>CDU</th>\n",
       "      <th>CSU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>cem_oezdemir</td>\n",
       "      <td>c_lindner</td>\n",
       "      <td>jensspahn</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joerg_Meuthen</td>\n",
       "      <td>GregorGysi</td>\n",
       "      <td>HeikoMaas</td>\n",
       "      <td>GoeringEckardt</td>\n",
       "      <td>MaStrackZi</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>DoroBaer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>katjakipping</td>\n",
       "      <td>OlafScholz</td>\n",
       "      <td>JTrittin</td>\n",
       "      <td>MarcoBuschmann</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>andreasscheuer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gottfriedcurio</td>\n",
       "      <td>DietmarBartsch</td>\n",
       "      <td>KuehniKev</td>\n",
       "      <td>KonstantinNotz</td>\n",
       "      <td>KonstantinKuhle</td>\n",
       "      <td>JuliaKloeckner</td>\n",
       "      <td>ManfredWeber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MalteKaufmann</td>\n",
       "      <td>anked</td>\n",
       "      <td>larsklingbeil</td>\n",
       "      <td>RenateKuenast</td>\n",
       "      <td>johannesvogel</td>\n",
       "      <td>n_roettgen</td>\n",
       "      <td>DerLenzMdB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JoanaCotar</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>hubertus_heil</td>\n",
       "      <td>Ricarda_Lang</td>\n",
       "      <td>Wissing</td>\n",
       "      <td>PaulZiemiak</td>\n",
       "      <td>hahnflo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tino_Chrupalla</td>\n",
       "      <td>jankortemdb</td>\n",
       "      <td>EskenSaskia</td>\n",
       "      <td>KathaSchulze</td>\n",
       "      <td>Lambsdorff</td>\n",
       "      <td>groehe</td>\n",
       "      <td>smuellermdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StBrandner</td>\n",
       "      <td>Janine_Wissler</td>\n",
       "      <td>Ralf_Stegner</td>\n",
       "      <td>BriHasselmann</td>\n",
       "      <td>ria_schroeder</td>\n",
       "      <td>HBraun</td>\n",
       "      <td>DaniLudwigMdB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GtzFrmming</td>\n",
       "      <td>SevimDagdelen</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>nouripour</td>\n",
       "      <td>LindaTeuteberg</td>\n",
       "      <td>rbrinkhaus</td>\n",
       "      <td>ANiebler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PetrBystronAFD</td>\n",
       "      <td>SusanneHennig</td>\n",
       "      <td>MiRo_SPD</td>\n",
       "      <td>MiKellner</td>\n",
       "      <td>f_schaeffler</td>\n",
       "      <td>tj_tweets</td>\n",
       "      <td>MarkusFerber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AFD           LINKE              SPD          GRUENE  \\\n",
       "0     Alice_Weidel    SWagenknecht  Karl_Lauterbach    cem_oezdemir   \n",
       "1    Joerg_Meuthen      GregorGysi        HeikoMaas  GoeringEckardt   \n",
       "2  Beatrix_vStorch    katjakipping       OlafScholz        JTrittin   \n",
       "3   gottfriedcurio  DietmarBartsch        KuehniKev  KonstantinNotz   \n",
       "4    MalteKaufmann           anked    larsklingbeil   RenateKuenast   \n",
       "5       JoanaCotar     b_riexinger    hubertus_heil    Ricarda_Lang   \n",
       "6   Tino_Chrupalla     jankortemdb      EskenSaskia    KathaSchulze   \n",
       "7       StBrandner  Janine_Wissler     Ralf_Stegner   BriHasselmann   \n",
       "8       GtzFrmming   SevimDagdelen     KarambaDiaby       nouripour   \n",
       "9   PetrBystronAFD   SusanneHennig         MiRo_SPD       MiKellner   \n",
       "\n",
       "               FDP             CDU             CSU  \n",
       "0        c_lindner       jensspahn   Markus_Soeder  \n",
       "1       MaStrackZi    ArminLaschet        DoroBaer  \n",
       "2   MarcoBuschmann  _FriedrichMerz  andreasscheuer  \n",
       "3  KonstantinKuhle  JuliaKloeckner    ManfredWeber  \n",
       "4    johannesvogel      n_roettgen      DerLenzMdB  \n",
       "5          Wissing     PaulZiemiak         hahnflo  \n",
       "6       Lambsdorff          groehe     smuellermdb  \n",
       "7    ria_schroeder          HBraun   DaniLudwigMdB  \n",
       "8   LindaTeuteberg      rbrinkhaus        ANiebler  \n",
       "9     f_schaeffler       tj_tweets    MarkusFerber  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432cc02f-6f4e-408e-9625-fbb10a2be41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_parties = pd.read_csv('../Datasets/accounts_parties.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d370f563-9870-455d-a96f-01c02e7dc620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFD</th>\n",
       "      <th>LINKE</th>\n",
       "      <th>SPD</th>\n",
       "      <th>GRUENE</th>\n",
       "      <th>FDP</th>\n",
       "      <th>CDU_CSU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AfD</td>\n",
       "      <td>dieLinke</td>\n",
       "      <td>spdde</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>fdp</td>\n",
       "      <td>CDU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AfDimBundestag</td>\n",
       "      <td>Linksfraktion</td>\n",
       "      <td>spdbt</td>\n",
       "      <td>GrueneBundestag</td>\n",
       "      <td>fdpbt</td>\n",
       "      <td>CSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfDBerlin</td>\n",
       "      <td>dielinkeberlin</td>\n",
       "      <td>jusos</td>\n",
       "      <td>gruene_jugend</td>\n",
       "      <td>fdp_nrw</td>\n",
       "      <td>cducsubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junge_Union</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AFD           LINKE    SPD           GRUENE      FDP  \\\n",
       "0             AfD        dieLinke  spdde      Die_Gruenen      fdp   \n",
       "1  AfDimBundestag   Linksfraktion  spdbt  GrueneBundestag    fdpbt   \n",
       "2       AfDBerlin  dielinkeberlin  jusos    gruene_jugend  fdp_nrw   \n",
       "3             NaN             NaN    NaN              NaN      NaN   \n",
       "\n",
       "       CDU_CSU  \n",
       "0          CDU  \n",
       "1          CSU  \n",
       "2     cducsubt  \n",
       "3  Junge_Union  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449efc4-0aca-41ec-acdd-e85f3aae99f8",
   "metadata": {},
   "source": [
    "### 5. Create Directories for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f6b071-a36c-479d-ac87-e83321d5c0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over the parties\n",
    "for party in PARTIES:\n",
    "    # Try to create the directory for the party in dataset folder\n",
    "    try:\n",
    "        os.makedirs(RAW_DATASET_PATH + party)\n",
    "    except FileExistsError:\n",
    "        # If the directory already exists pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c673833-34e2-4c99-8410-2854c23e5230",
   "metadata": {},
   "source": [
    "### 6. Download Tweets by Politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db26f5bd-8fe4-4295-8145-8c862e3b24f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 1 | Party: AFD | Account: @Alice_Weidel\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'place'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'place'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m new_tweets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_party\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m party\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Remove place column (as this column had problems regarding the data type and is irrelevant for our analyses)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m new_tweets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplace\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Append the new tweets to the dataset\u001b[39;00m\n\u001b[1;32m     42\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dataset, new_tweets], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/pandas/core/generic.py:4243\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4238\u001b[0m             deleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   4239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m deleted:\n\u001b[1;32m   4240\u001b[0m     \u001b[38;5;66;03m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[1;32m   4241\u001b[0m     \u001b[38;5;66;03m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[1;32m   4242\u001b[0m     \u001b[38;5;66;03m# exception:\u001b[39;00m\n\u001b[0;32m-> 4243\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39midelete(loc)\n\u001b[1;32m   4246\u001b[0m \u001b[38;5;66;03m# delete from the caches\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'place'"
     ]
    }
   ],
   "source": [
    "for party, col_data in df_politicians.items():\n",
    "    # Iterate over the accounts of the current party\n",
    "    for itr, account_name in enumerate(col_data.to_numpy()):\n",
    "        # tweets by the parties CDU and CSU will be stored in the same directory\n",
    "        if party in [\"CDU\", \"CSU\"]:\n",
    "            party = \"CDU_CSU\"\n",
    "            \n",
    "        # Print account name of current iteration\n",
    "        print(f'Current Iteration: {itr+1} | Party: {party} | Account: @{account_name}')\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the tweets for a party account\n",
    "        dataset = pd.DataFrame()\n",
    "        \n",
    "        # Iterate over the months of the year\n",
    "        for month in range(1, 13):\n",
    "            # Initialize an empty list to store the random days for the current month and account\n",
    "            random_days = []\n",
    "            \n",
    "            # Iterate over the number of days to crawl per account\n",
    "            for i in range(N_DAYS_PER_ACCOUNT):\n",
    "                random_day_found = False\n",
    "                \n",
    "                # Keep trying to find a random day that has not been used before\n",
    "                while not(random_day_found):\n",
    "                    # Get the start and end dates for a random day in the month\n",
    "                    random_day, following_day = get_random_day_and_next(month)\n",
    "                    if not(random_day in random_days):\n",
    "                        random_days.append(random_day)\n",
    "                        random_day_found = True\n",
    "            \n",
    "                # Get tweets for the specified day\n",
    "                new_tweets = get_tweets_for_specific_day(query=f\"@{account_name}\", since=random_day, until=following_day)\n",
    "                \n",
    "                # Save the information for which account the tweet was crawled\n",
    "                new_tweets['source_account'] = account_name\n",
    "                new_tweets['source_party'] = party\n",
    "                \n",
    "                # Remove place column (as this column had problems regarding the data type and is irrelevant for our analyses)\n",
    "                try:\n",
    "                    del new_tweets['place']\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Append the new tweets to the dataset\n",
    "                dataset = pd.concat([dataset, new_tweets], axis=0).reset_index().drop(columns='index')\n",
    "            \n",
    "        # Remove all line breaks from the values in the \"tweet\" row\n",
    "        dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub(r'\\r\\n|\\r|\\n', '', x))\n",
    "        \n",
    "        # Save the dataset to a CSV file\n",
    "        dataset.to_csv(f\"../Datasets/raw_dataset/{party}/{account_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7b292-40d0-429a-a6d0-8ebafeb3aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, localtime\n",
    "localtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087462b-9e41-4c6b-a412-c8335d470f80",
   "metadata": {},
   "source": [
    "### 7. Download Tweets From Party Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33747f6-5517-4988-ad15-d02833a2885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for party, col_data in df_parties.items():\n",
    "    # Iterate over the accounts of the current party\n",
    "    # It is checked if a value is NaN, because only CDU and CSU have a fourth account, which we consider\n",
    "    for itr, account_name in enumerate(col_data.to_numpy()[~pd.isnull(col_data.to_numpy())]):\n",
    "        # Print account name of current iteration\n",
    "        print(f'Current Iteration: {itr+1} | Party: {party} | Account: @{account_name}')\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the tweets for a party account\n",
    "        dataset = pd.DataFrame()\n",
    "        \n",
    "        # Iterate over the months of the year\n",
    "        for month in range(1, 13):\n",
    "            # Initialize an empty list to store the random days for the current month and account\n",
    "            random_days = []\n",
    "            \n",
    "            # Iterate over the number of days to crawl per account\n",
    "            for i in range(N_DAYS_PER_ACCOUNT):\n",
    "                random_day_found = False\n",
    "                \n",
    "                # Keep trying to find a random day that has not been used before\n",
    "                while not(random_day_found):\n",
    "                    # Get the start and end dates for a random day in the month\n",
    "                    random_day, following_day = get_random_day_and_next(month)\n",
    "\n",
    "                    if not(random_day in random_days):\n",
    "                        random_days.append(random_day)\n",
    "                        random_day_found = True\n",
    "\n",
    "                # Get tweets for the specified day\n",
    "                new_tweets = get_tweets_for_specific_day(query=f\"@{account_name}\", since=random_day, until=following_day)\n",
    "                \n",
    "                # Save the information for which account the tweet was crawled\n",
    "                new_tweets['source_account'] = account_name\n",
    "                new_tweets['source_party'] = party\n",
    "                \n",
    "                # Append the new tweets to the dataset\n",
    "                dataset = pd.concat([dataset, new_tweets], axis=0).reset_index().drop(columns='index')\n",
    "        \n",
    "        # Remove all line breaks from the values in the \"tweet\" column\n",
    "        dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub(r'\\r\\n|\\r|\\n', '', x))\n",
    "        \n",
    "        # Save the dataset to a CSV file\n",
    "        dataset.to_csv(f\"../Datasets/raw_dataset/{party}/{account_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
