{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfe2851-4e1f-4439-b563-ab3d3cdcfe6d",
   "metadata": {},
   "source": [
    "# Notebook: Create Twitter Dataset\n",
    "\n",
    "This notebook is used to crawl tweets mentioning the 89 relevant Twitter accounts of German politicians.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087016ed-05ff-4887-b8ca-ce6d91506a38",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b664e9-31d5-469d-99fd-ce1aa607de87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import random\n",
    "import twint\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf88f6-b7cd-4989-b099-658fe967c01f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de32ef-c206-4ccd-9b76-29a638c73ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATASET_PATH = '../Datasets/raw_dataset/'\n",
    "SEED_VALUE = 0\n",
    "N_DAYS_PER_ACCOUNT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8462ded0-a975-4af7-aa5e-5b81d33951db",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5c562-8aaf-4aa2-aadb-27ce6273096f",
   "metadata": {},
   "source": [
    "### 1. Get Reproducable Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b145c-ad6b-4cd7-9772-cc62e546201c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4e085-080e-40e0-9fb5-90ee2f087f15",
   "metadata": {},
   "source": [
    "### 2. Function to get a random day in one of the 12 months in 2021 (as well as the next day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2d496-d057-4c78-8a1f-95216a5dda5b",
   "metadata": {},
   "source": [
    "Twint expects a date in the format of `%Y-%m-%d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64f87d-f360-4920-99f2-7c7b27e8b09f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_day_and_next(month: int) -> tuple:\n",
    "    # Validate the month input\n",
    "    if not 1 <= month <= 12:\n",
    "        raise ValueError(\"Month must be an integer between 1 and 12\")\n",
    "\n",
    "    # Get the number of days in a specific month\n",
    "    num_days = calendar.monthrange(2021, month)[1]\n",
    "\n",
    "    # Get random day in the month\n",
    "    day = random.randint(1, num_days)\n",
    "\n",
    "    # Format date as a string\n",
    "    date_str = f\"2021-{month:02d}-{day:02d}\"\n",
    "\n",
    "    # Convert the date string to a datetime object\n",
    "    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    # Calculate the next day\n",
    "    next_day = date + timedelta(days=1)\n",
    "\n",
    "    # Return the date and next day as a tuple\n",
    "    return (date.strftime(\"%Y-%m-%d\"), next_day.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4486b-6067-4444-a8e0-57d308ad15d3",
   "metadata": {},
   "source": [
    "Test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9633a1-7de8-4a98-8f2d-2d87f7f3bc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_day, following_day = get_random_day_and_next(4)\n",
    "\n",
    "print(f\"Random day: {random_day}\")\n",
    "print(f\"Following day: {following_day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb5078b-c603-4bb6-a21c-aecc984577c6",
   "metadata": {},
   "source": [
    "### 3. Function to retrieve all tweets with a specific @-mention and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14a551-6d57-4d06-8152-8f8cbcab94bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tweets_for_specific_day(query: str, since: str, until:str):\n",
    "    nest_asyncio.apply()\n",
    "    config = twint.Config()\n",
    "    \n",
    "    config.Search = query  # Set the search query\n",
    "    config.Limit = 9000000000  # Set a very large limit to retrieve all tweets for a day\n",
    "    config.Since = since  # Set the start date for the search\n",
    "    config.Until = until  # Set the end date for the search\n",
    "    config.Pandas = True  # Return the results as a Pandas DataFrame\n",
    "    config.Hide_output = True  # Suppress console output\n",
    "    \n",
    "    twint.run.Search(config)\n",
    "    return twint.storage.panda.Tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68f96f-a37e-4423-943c-1f60fe3f3ce1",
   "metadata": {},
   "source": [
    "### 4. Load Accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca581ec4-7a02-4db2-a886-476afb816445",
   "metadata": {},
   "source": [
    "#### Politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e558cd-03cc-4fad-ad0b-8de94205655e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_politicians = pd.read_csv('../Datasets/accounts_politicians.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21790d46-c7b6-4026-b771-cdda3a67f6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cc02f-6f4e-408e-9625-fbb10a2be41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_parties = pd.read_csv('../Datasets/accounts_parties.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370f563-9870-455d-a96f-01c02e7dc620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449efc4-0aca-41ec-acdd-e85f3aae99f8",
   "metadata": {},
   "source": [
    "### 5. Create Directories for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6b071-a36c-479d-ac87-e83321d5c0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of parties\n",
    "parties = ['CDU_CSU', 'FDP', 'AFD', 'LINKE', 'SPD', 'GRUENE']\n",
    "\n",
    "# Iterate over the parties\n",
    "for party in parties:\n",
    "    # Try to create the directory for the party in dataset folder\n",
    "    try:\n",
    "        os.makedirs(RAW_DATASET_PATH + party)\n",
    "    except FileExistsError:\n",
    "        # If the directory already exists pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c673833-34e2-4c99-8410-2854c23e5230",
   "metadata": {},
   "source": [
    "### 6. Download Tweets by Politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26f5bd-8fe4-4295-8145-8c862e3b24f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for party, col_data in df_politicians.iteritems():\n",
    "    # Iterate over the accounts of the current party\n",
    "    for itr, account_name in enumerate(col_data.to_numpy()):\n",
    "        # Print account name of current iteration\n",
    "        print(f'Current Iteration: {itr+1} | Party: {party} | Account: @{account_name}')\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the tweets for a party account\n",
    "        dataset = pd.DataFrame()\n",
    "        \n",
    "        # Iterate over the months of the year\n",
    "        for month in range(1, 13):\n",
    "            # Initialize an empty list to store the random days for the current month and account\n",
    "            random_days = []\n",
    "            \n",
    "            # Iterate over the number of days to crawl per account\n",
    "            for i in range(N_DAYS_PER_ACCOUNT):\n",
    "                random_day_found = False\n",
    "                \n",
    "                # Keep trying to find a random day that has not been used before\n",
    "                while not(random_day_found):\n",
    "                    # Get the start and end dates for a random day in the month\n",
    "                    random_day, following_day = get_random_day_and_next(month)\n",
    "                    if not(random_day in random_days):\n",
    "                        random_days.append(random_day)\n",
    "                        random_day_found = True\n",
    "            \n",
    "                # Get tweets for the specified day\n",
    "                new_tweets = get_tweets_for_specific_day(query=f\"@{account_name}\", since=random_day, until=following_day)\n",
    "                \n",
    "                # Save the information for which account the tweet was crawled\n",
    "                new_tweets['source_account'] = account_name\n",
    "                new_tweets['source_party'] = party\n",
    "                \n",
    "                # Append the new tweets to the dataset\n",
    "                dataset = pd.concat([dataset, new_tweets], axis=0).reset_index().drop(columns='index')\n",
    "        \n",
    "        # tweets by the parties CDU and CSU will be stored in the same directory\n",
    "        if party in [\"CDU\", \"CSU\"]:\n",
    "            party = \"CDU_CSU\"\n",
    "            \n",
    "        # Remove all line breaks from the values in the \"tweet\" row\n",
    "        dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub(r'\\r\\n|\\r|\\n', '', x))\n",
    "        \n",
    "        # Save the dataset to a CSV file\n",
    "        dataset.to_csv(f\"../Datasets/raw_dataset/{party}/{account_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087462b-9e41-4c6b-a412-c8335d470f80",
   "metadata": {},
   "source": [
    "### 7. Download Tweets From Party Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33747f6-5517-4988-ad15-d02833a2885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for party, col_data in df_parties.iteritems():\n",
    "    # Iterate over the accounts of the current party\n",
    "    # It is checked if a value is NaN, because only CDU and CSU have a fourth account, which we consider\n",
    "    for itr, account_name in enumerate(col_data.to_numpy()[~pd.isnull(col_data.to_numpy())]):\n",
    "        # Print account name of current iteration\n",
    "        print(f'Current Iteration: {itr+1} | Party: {party} | Account: @{account_name}')\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the tweets for a party account\n",
    "        dataset = pd.DataFrame()\n",
    "        \n",
    "        # Iterate over the months of the year\n",
    "        for month in range(1, 13):\n",
    "            # Initialize an empty list to store the random days for the current month and account\n",
    "            random_days = []\n",
    "            \n",
    "            # Iterate over the number of days to crawl per account\n",
    "            for i in range(N_DAYS_PER_ACCOUNT):\n",
    "                random_day_found = False\n",
    "                \n",
    "                # Keep trying to find a random day that has not been used before\n",
    "                while not(random_day_found):\n",
    "                    # Get the start and end dates for a random day in the month\n",
    "                    random_day, following_day = get_random_day_and_next(month)\n",
    "\n",
    "                    if not(random_day in random_days):\n",
    "                        random_days.append(random_day)\n",
    "                        random_day_found = True\n",
    "\n",
    "                # Get tweets for the specified day\n",
    "                new_tweets = get_tweets_for_specific_day(query=f\"@{account_name}\", since=random_day, until=following_day)\n",
    "                \n",
    "                # Save the information for which account the tweet was crawled\n",
    "                new_tweets['source_account'] = account_name\n",
    "                new_tweets['source_party'] = party\n",
    "                \n",
    "                # Append the new tweets to the dataset\n",
    "                dataset = pd.concat([dataset, new_tweets], axis=0).reset_index().drop(columns='index')\n",
    "        \n",
    "        # Remove all line breaks from the values in the \"tweet\" column\n",
    "        dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub(r'\\r\\n|\\r|\\n', '', x))\n",
    "        \n",
    "        # Save the dataset to a CSV file\n",
    "        dataset.to_csv(f\"../Datasets/raw_dataset/{party}/{account_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
