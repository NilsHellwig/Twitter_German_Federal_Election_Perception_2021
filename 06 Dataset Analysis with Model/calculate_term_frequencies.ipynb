{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca11e4c2-f017-4781-94eb-944d94d485ec",
   "metadata": {},
   "source": [
    "# Notebook: Create Term Frequency Analysis \n",
    "\n",
    "This notebook is used to calculate term frequencies.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fc444-d02e-4a9b-83be-63c822dc5a51",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e90d190-1849-49ce-b70a-e3f971cd45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from reportlab.graphics import renderPDF\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from svglib.svglib import svg2rlg\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12a912-011f-4712-90ad-0554d5ca1195",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d18b20-a288-43b6-b029-d57ff0c3f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTIES = [\"SPD\", \"CDU_CSU\", \"GRUENE\", \"FDP\", \"AFD\", \"LINKE\"]\n",
    "DATASET_PATH_PREDICTIONS =  \"../Datasets/complete_dataset_predictions/\"\n",
    "DATASET_PATH = \"../Datasets/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3893e6a-703f-457b-8c2d-3904dbf48e07",
   "metadata": {},
   "source": [
    "## Setup Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dbc081-e610-489b-af0a-9c1ea99c2d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words(\"german\"))\n",
    "STOPWORDS.update([\"mehr\", \"heute\",\"https\", \"bundestag\", \"thread\", \"anzeigen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb41670-3837-4780-b007-35254a250918",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290fb47-0291-4be8-8f9d-3fc1a36624a0",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cb2a12-6241-44e0-98cd-63a8f550acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "\n",
    "for party in PARTIES:\n",
    "    for subdir, _, files in os.walk(DATASET_PATH_PREDICTIONS + party):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and subdir[len(DATASET_PATH_PREDICTIONS):] in PARTIES:\n",
    "                # Get username of CSV file\n",
    "                username = file[:-4]\n",
    "                \n",
    "                # Read CSV file as pandas dataframe\n",
    "                df_acc_data = pd.read_csv(DATASET_PATH + party + \"/\" + file)\n",
    "                ids = df_acc_data[\"id\"].values\n",
    "                df_acc_data = df_acc_data[[\"tweet\", \"source_party\", \"source_account\", \"date\"]].reset_index().drop(columns='index')\n",
    "                \n",
    "                df_pred = pd.read_csv(DATASET_PATH_PREDICTIONS + party + \"/\" + file)\n",
    "                df_pred = df_pred[df_pred[\"id\"].isin(ids)][[\"pred\"]].reset_index().drop(columns='index')\n",
    "                \n",
    "                matched_df = pd.concat([df_acc_data, df_pred], axis=1)\n",
    "                matched_df = matched_df.rename(columns={\"pred\": \"sentiment\", \"tweet\": \"text\"})\n",
    "                \n",
    "                df = pd.concat([df, matched_df], axis=0)\n",
    "\n",
    "df = df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afcd2f9-f7ce-4a4a-950e-800bce893cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source_party</th>\n",
       "      <th>source_account</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wichtige wissenschaftliche Erkenntnis- nun mus...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 19:35:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Ich gratulier...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 17:09:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Herzlichen Gl...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 13:16:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Wann werden k...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 12:32:40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Glückwunsch.</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 12:13:06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707236</th>\n",
       "      <td>@b_riexinger Klima oder Verkehr fast gleich......</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 08:19:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707237</th>\n",
       "      <td>@b_riexinger @Linksfraktion Na ob das noch lan...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 08:18:07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707238</th>\n",
       "      <td>@b_riexinger Ich wünsch Dir viel Erfolg.</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 07:47:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707239</th>\n",
       "      <td>@b_riexinger Nun, da gibt es ja genügend zu tu...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 02:07:26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707240</th>\n",
       "      <td>@b_riexinger Wünsche dir gutes Gelingen lieber...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 01:02:05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707241 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text source_party  \\\n",
       "0       Wichtige wissenschaftliche Erkenntnis- nun mus...          SPD   \n",
       "1       @KarambaDiaby @HalleSpd @SPD_LSA Ich gratulier...          SPD   \n",
       "2       @KarambaDiaby @HalleSpd @SPD_LSA Herzlichen Gl...          SPD   \n",
       "3       @KarambaDiaby @HalleSpd @SPD_LSA Wann werden k...          SPD   \n",
       "4           @KarambaDiaby @HalleSpd @SPD_LSA Glückwunsch.          SPD   \n",
       "...                                                   ...          ...   \n",
       "707236  @b_riexinger Klima oder Verkehr fast gleich......        LINKE   \n",
       "707237  @b_riexinger @Linksfraktion Na ob das noch lan...        LINKE   \n",
       "707238           @b_riexinger Ich wünsch Dir viel Erfolg.        LINKE   \n",
       "707239  @b_riexinger Nun, da gibt es ja genügend zu tu...        LINKE   \n",
       "707240  @b_riexinger Wünsche dir gutes Gelingen lieber...        LINKE   \n",
       "\n",
       "       source_account                 date  sentiment  \n",
       "0        KarambaDiaby  2021-01-09 19:35:29          0  \n",
       "1        KarambaDiaby  2021-01-09 17:09:28          0  \n",
       "2        KarambaDiaby  2021-01-09 13:16:13          0  \n",
       "3        KarambaDiaby  2021-01-09 12:32:40          1  \n",
       "4        KarambaDiaby  2021-01-09 12:13:06          0  \n",
       "...               ...                  ...        ...  \n",
       "707236    b_riexinger  2021-12-17 08:19:23          1  \n",
       "707237    b_riexinger  2021-12-17 08:18:07          1  \n",
       "707238    b_riexinger  2021-12-17 07:47:59          0  \n",
       "707239    b_riexinger  2021-12-17 02:07:26          2  \n",
       "707240    b_riexinger  2021-12-17 01:02:05          0  \n",
       "\n",
       "[707241 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcd065-76d6-4103-af4a-8423fdef787c",
   "metadata": {},
   "source": [
    "Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800b8d3c-26c6-4661-83c3-1016eaf03c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_twitter_mentions(text):\n",
    "    regex = r\"@[a-zA-Z0-9_]+\"\n",
    "    return re.sub(regex, \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35718b1f-3ca6-41f6-abb9-e5c7c76e5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
    "    \n",
    "    text = re.sub(RE_TAGS, \" \", text)\n",
    "    text = re.sub(RE_ASCII, \" \", text)\n",
    "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
    "    text = re.sub(RE_WSPACE, \" \", text)\n",
    "    \n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [word.lower() for word in word_tokens]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcb3eb2-dc02-4a70-9233-ce4d26917e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(remove_twitter_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e2f5b5-f607-4584-9e45-c7f6d55c04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae5bdc-c782-4325-8a06-412798295b4a",
   "metadata": {},
   "source": [
    "### 2. Calculate Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3320842-4d3d-4ec5-a08c-01c62e1176ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequencies(data):\n",
    "    text = data['text']\n",
    "    count_vect = CountVectorizer(max_features=100)\n",
    "    tf_matrix = count_vect.fit_transform(text)\n",
    "    feature_names = list(count_vect.vocabulary_.keys())\n",
    "\n",
    "    tf_df = pd.DataFrame(tf_matrix.toarray(), columns=feature_names)\n",
    "    word_counts = tf_df.sum(axis=0)\n",
    "    word_counts_sorted = word_counts.sort_values(ascending=False)\n",
    "\n",
    "    # Die ersten 50 häufigsten Wörter ausgeben\n",
    "    top_words = word_counts_sorted.head(50).to_frame().reset_index()\n",
    "    top_words.columns = ['word', 'count']\n",
    "    top_words.style.format({'count': '{:,}'})\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5e74f-d4b0-47a4-96d2-d03322c7e568",
   "metadata": {},
   "source": [
    "#### 2.1 Calculate Word Frequencies for Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a81798-c291-4a00-9142-755947a18ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word   count\n",
      "0        der  439060\n",
      "1      warum  321580\n",
      "2      schon  287935\n",
      "3       über  245206\n",
      "4        was  240565\n",
      "5        mit  228379\n",
      "6      keine  164298\n",
      "7       mehr  162743\n",
      "8      alles  158274\n",
      "9         er  150885\n",
      "10    können  140028\n",
      "11       aus  120761\n",
      "12       bei  116420\n",
      "13       wir  113006\n",
      "14     nicht  112205\n",
      "15       vor   99765\n",
      "16       war   91454\n",
      "17       ein   91096\n",
      "18       mir   84633\n",
      "19      muss   83107\n",
      "20    wieder   82911\n",
      "21       zum   81077\n",
      "22      wird   80559\n",
      "23     jetzt   78652\n",
      "24      aber   77833\n",
      "25       den   77792\n",
      "26  menschen   76228\n",
      "27        im   74839\n",
      "28        ja   74605\n",
      "29       sie   74507\n",
      "30     diese   71456\n",
      "31       dem   70460\n",
      "32       als   70269\n",
      "33       die   63710\n",
      "34        um   63683\n",
      "35     einen   61312\n",
      "36      viel   61127\n",
      "37      sind   61109\n",
      "38      nach   59732\n",
      "39       mal   59497\n",
      "40       auf   54561\n",
      "41      wenn   54416\n",
      "42     einer   53597\n",
      "43    machen   52836\n",
      "44      ihre   52263\n",
      "45       des   51736\n",
      "46      kann   49484\n",
      "47      sein   49151\n",
      "48        zu   46905\n",
      "49      hier   46568\n"
     ]
    }
   ],
   "source": [
    "print(get_word_frequencies(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c413ba-ec95-45a5-9cff-e8c8ef66c727",
   "metadata": {},
   "source": [
    "#### 2.2 Calculate Word Frequencies for specific time/sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35de248e-07b1-45bc-ac8b-009b503efe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word  count\n",
      "0      muss    501\n",
      "1      alle    366\n",
      "2       zur    311\n",
      "3        zu    268\n",
      "4        du    232\n",
      "5      herr    195\n",
      "6       der    193\n",
      "7    können    167\n",
      "8       vor    151\n",
      "9       ein    141\n",
      "10      das    135\n",
      "11    schon    132\n",
      "12     wird    126\n",
      "13    jetzt    121\n",
      "14      von    121\n",
      "15      den    114\n",
      "16      fdp    114\n",
      "17     kann    114\n",
      "18       an    110\n",
      "19    haben    107\n",
      "20    https    103\n",
      "21    bitte    103\n",
      "22     ihre     88\n",
      "23      aus     86\n",
      "24     doch     83\n",
      "25      wie     82\n",
      "26      hat     81\n",
      "27     gute     81\n",
      "28     mich     77\n",
      "29      des     77\n",
      "30      mir     76\n",
      "31      war     72\n",
      "32      und     70\n",
      "33     dank     68\n",
      "34     wenn     66\n",
      "35      ich     65\n",
      "36      als     65\n",
      "37       in     63\n",
      "38    immer     63\n",
      "39     sein     62\n",
      "40    alles     59\n",
      "41     habe     59\n",
      "42     eine     58\n",
      "43     dann     55\n",
      "44     sind     54\n",
      "45  lindner     53\n",
      "46     aber     53\n",
      "47      dem     50\n",
      "48      amp     48\n",
      "49   wieder     48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/5gtwsk6s7jgbknbqgb533x9w0000gn/T/ipykernel_70195/3892991061.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(get_word_frequencies(df[df[\"source_party\"] == \"FDP\"][pd.to_datetime(df[\"date\"]).dt.month == 11][df[\"sentiment\"] == 0]))\n"
     ]
    }
   ],
   "source": [
    "print(get_word_frequencies(df[df[\"source_party\"] == \"FDP\"][pd.to_datetime(df[\"date\"]).dt.month == 11][df[\"sentiment\"] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbaf306-a9ac-4369-ac7f-3f306e15050a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
