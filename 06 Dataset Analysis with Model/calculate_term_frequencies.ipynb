{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca11e4c2-f017-4781-94eb-944d94d485ec",
   "metadata": {},
   "source": [
    "# Notebook: Create Term Frequency Analysis \n",
    "\n",
    "This notebook is used to calculate term frequencies.\n",
    "<br>**Contributors:** [Nils Hellwig](https://github.com/NilsHellwig/) | [Markus Bink](https://github.com/MarkusBink/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fc444-d02e-4a9b-83be-63c822dc5a51",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e90d190-1849-49ce-b70a-e3f971cd45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from reportlab.graphics import renderPDF\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from svglib.svglib import svg2rlg\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12a912-011f-4712-90ad-0554d5ca1195",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d18b20-a288-43b6-b029-d57ff0c3f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTIES = [\"SPD\", \"CDU_CSU\", \"GRUENE\", \"FDP\", \"AFD\", \"LINKE\"]\n",
    "DATASET_PATH_PREDICTIONS =  \"../Datasets/complete_dataset_predictions/\"\n",
    "DATASET_PATH = \"../Datasets/dataset/\"\n",
    "OUTPUT_DIR = \"../Word Frequencies/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3893e6a-703f-457b-8c2d-3904dbf48e07",
   "metadata": {},
   "source": [
    "## Setup Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dbc081-e610-489b-af0a-9c1ea99c2d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/markusbink/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/markusbink/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words(\"german\"))\n",
    "STOPWORDS.update([\"mehr\", \"heute\",\"https\", \"bundestag\", \"thread\", \"anzeigen\", \"https\", \"http\", \"www\", \"co\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb41670-3837-4780-b007-35254a250918",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290fb47-0291-4be8-8f9d-3fc1a36624a0",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31cb2a12-6241-44e0-98cd-63a8f550acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "\n",
    "for party in PARTIES:\n",
    "    for subdir, _, files in os.walk(DATASET_PATH_PREDICTIONS + party):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and subdir[len(DATASET_PATH_PREDICTIONS):] in PARTIES:\n",
    "                # Get username of CSV file\n",
    "                username = file[:-4]\n",
    "                \n",
    "                # Read CSV file as pandas dataframe\n",
    "                df_acc_data = pd.read_csv(DATASET_PATH + party + \"/\" + file)\n",
    "                ids = df_acc_data[\"id\"].values\n",
    "                df_acc_data = df_acc_data[[\"tweet\", \"source_party\", \"source_account\", \"date\"]].reset_index().drop(columns='index')\n",
    "                \n",
    "                df_pred = pd.read_csv(DATASET_PATH_PREDICTIONS + party + \"/\" + file)\n",
    "                df_pred = df_pred[df_pred[\"id\"].isin(ids)][[\"pred\"]].reset_index().drop(columns='index')\n",
    "                \n",
    "                matched_df = pd.concat([df_acc_data, df_pred], axis=1)\n",
    "                matched_df = matched_df.rename(columns={\"pred\": \"sentiment\", \"tweet\": \"text\"})\n",
    "                \n",
    "                df = pd.concat([df, matched_df], axis=0)\n",
    "\n",
    "df = df.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afcd2f9-f7ce-4a4a-950e-800bce893cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source_party</th>\n",
       "      <th>source_account</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wichtige wissenschaftliche Erkenntnis- nun mus...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 19:35:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Ich gratulier...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 17:09:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Herzlichen Gl...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 13:16:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Wann werden k...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 12:32:40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@KarambaDiaby @HalleSpd @SPD_LSA Glückwunsch.</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 12:13:06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707236</th>\n",
       "      <td>@b_riexinger Klima oder Verkehr fast gleich......</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 08:19:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707237</th>\n",
       "      <td>@b_riexinger @Linksfraktion Na ob das noch lan...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 08:18:07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707238</th>\n",
       "      <td>@b_riexinger Ich wünsch Dir viel Erfolg.</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 07:47:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707239</th>\n",
       "      <td>@b_riexinger Nun, da gibt es ja genügend zu tu...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 02:07:26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707240</th>\n",
       "      <td>@b_riexinger Wünsche dir gutes Gelingen lieber...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 01:02:05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707241 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text source_party  \\\n",
       "0       Wichtige wissenschaftliche Erkenntnis- nun mus...          SPD   \n",
       "1       @KarambaDiaby @HalleSpd @SPD_LSA Ich gratulier...          SPD   \n",
       "2       @KarambaDiaby @HalleSpd @SPD_LSA Herzlichen Gl...          SPD   \n",
       "3       @KarambaDiaby @HalleSpd @SPD_LSA Wann werden k...          SPD   \n",
       "4           @KarambaDiaby @HalleSpd @SPD_LSA Glückwunsch.          SPD   \n",
       "...                                                   ...          ...   \n",
       "707236  @b_riexinger Klima oder Verkehr fast gleich......        LINKE   \n",
       "707237  @b_riexinger @Linksfraktion Na ob das noch lan...        LINKE   \n",
       "707238           @b_riexinger Ich wünsch Dir viel Erfolg.        LINKE   \n",
       "707239  @b_riexinger Nun, da gibt es ja genügend zu tu...        LINKE   \n",
       "707240  @b_riexinger Wünsche dir gutes Gelingen lieber...        LINKE   \n",
       "\n",
       "       source_account                 date  sentiment  \n",
       "0        KarambaDiaby  2021-01-09 19:35:29          0  \n",
       "1        KarambaDiaby  2021-01-09 17:09:28          0  \n",
       "2        KarambaDiaby  2021-01-09 13:16:13          0  \n",
       "3        KarambaDiaby  2021-01-09 12:32:40          1  \n",
       "4        KarambaDiaby  2021-01-09 12:13:06          0  \n",
       "...               ...                  ...        ...  \n",
       "707236    b_riexinger  2021-12-17 08:19:23          1  \n",
       "707237    b_riexinger  2021-12-17 08:18:07          1  \n",
       "707238    b_riexinger  2021-12-17 07:47:59          0  \n",
       "707239    b_riexinger  2021-12-17 02:07:26          2  \n",
       "707240    b_riexinger  2021-12-17 01:02:05          0  \n",
       "\n",
       "[707241 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcd065-76d6-4103-af4a-8423fdef787c",
   "metadata": {},
   "source": [
    "Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800b8d3c-26c6-4661-83c3-1016eaf03c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_twitter_mentions(text):\n",
    "    regex = r\"@[a-zA-Z0-9_]+\"\n",
    "    return re.sub(regex, \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35718b1f-3ca6-41f6-abb9-e5c7c76e5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
    "    \n",
    "    text = re.sub(RE_TAGS, \" \", text)\n",
    "    text = re.sub(RE_ASCII, \" \", text)\n",
    "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
    "    text = re.sub(RE_WSPACE, \" \", text)\n",
    "    \n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [word.lower() for word in word_tokens if word.lower() not in STOPWORDS]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbcb3eb2-dc02-4a70-9233-ce4d26917e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(remove_twitter_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e2f5b5-f607-4584-9e45-c7f6d55c04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f9e259-8918-411e-b5bd-2f9cd911de8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source_party</th>\n",
       "      <th>source_account</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wichtige wissenschaftliche erkenntnis schnell ...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 19:35:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gratuliere linken</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 17:09:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>herzlichen glückwunsch erfolg</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 13:16:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wann konkret massiv steuern sozialabgaben gese...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 12:32:40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glückwunsch</td>\n",
       "      <td>SPD</td>\n",
       "      <td>KarambaDiaby</td>\n",
       "      <td>2021-01-09 12:13:06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707236</th>\n",
       "      <td>klima verkehr fast gleich hauptsache pöstchen</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 08:19:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707237</th>\n",
       "      <td>na lange gut geht gruppierungen querdenker lin...</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 08:18:07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707238</th>\n",
       "      <td>wünsch erfolg</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 07:47:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707239</th>\n",
       "      <td>gibt ja genügend tuen paris macht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 02:07:26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707240</th>\n",
       "      <td>wünsche gutes gelingen lieber bernd linkspower</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>b_riexinger</td>\n",
       "      <td>2021-12-17 01:02:05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707241 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text source_party  \\\n",
       "0       wichtige wissenschaftliche erkenntnis schnell ...          SPD   \n",
       "1                                       gratuliere linken          SPD   \n",
       "2                           herzlichen glückwunsch erfolg          SPD   \n",
       "3       wann konkret massiv steuern sozialabgaben gese...          SPD   \n",
       "4                                             glückwunsch          SPD   \n",
       "...                                                   ...          ...   \n",
       "707236      klima verkehr fast gleich hauptsache pöstchen        LINKE   \n",
       "707237  na lange gut geht gruppierungen querdenker lin...        LINKE   \n",
       "707238                                      wünsch erfolg        LINKE   \n",
       "707239                  gibt ja genügend tuen paris macht        LINKE   \n",
       "707240     wünsche gutes gelingen lieber bernd linkspower        LINKE   \n",
       "\n",
       "       source_account                 date  sentiment  \n",
       "0        KarambaDiaby  2021-01-09 19:35:29          0  \n",
       "1        KarambaDiaby  2021-01-09 17:09:28          0  \n",
       "2        KarambaDiaby  2021-01-09 13:16:13          0  \n",
       "3        KarambaDiaby  2021-01-09 12:32:40          1  \n",
       "4        KarambaDiaby  2021-01-09 12:13:06          0  \n",
       "...               ...                  ...        ...  \n",
       "707236    b_riexinger  2021-12-17 08:19:23          1  \n",
       "707237    b_riexinger  2021-12-17 08:18:07          1  \n",
       "707238    b_riexinger  2021-12-17 07:47:59          0  \n",
       "707239    b_riexinger  2021-12-17 02:07:26          2  \n",
       "707240    b_riexinger  2021-12-17 01:02:05          0  \n",
       "\n",
       "[707241 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae5bdc-c782-4325-8a06-412798295b4a",
   "metadata": {},
   "source": [
    "### 2. Calculate Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edc2426-72fd-4717-90cd-6907a5df197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_as_name(sentiment_code):\n",
    "    if sentiment_code == 0:\n",
    "        return \"positive\"\n",
    "    if sentiment_code == 1:\n",
    "        return \"negative\"\n",
    "    if sentiment_code == 2: \n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e382ae-1461-444e-b6fd-3760d8e425c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_code(month_num):\n",
    "    if month_num == 1:\n",
    "        return \"January\"\n",
    "    elif month_num == 2:\n",
    "        return \"February\"\n",
    "    elif month_num == 3:\n",
    "        return \"March\"\n",
    "    elif month_num == 4:\n",
    "        return \"April\"\n",
    "    elif month_num == 5:\n",
    "        return \"May\"\n",
    "    elif month_num == 6:\n",
    "        return \"June\"\n",
    "    elif month_num == 7:\n",
    "        return \"July\"\n",
    "    elif month_num == 8:\n",
    "        return \"August\"\n",
    "    elif month_num == 9:\n",
    "        return \"September\"\n",
    "    elif month_num == 10:\n",
    "        return \"October\"\n",
    "    elif month_num == 11:\n",
    "        return \"November\"\n",
    "    elif month_num == 12:\n",
    "        return \"December\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3320842-4d3d-4ec5-a08c-01c62e1176ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequencies(data):\n",
    "    text = data['text']\n",
    "    count_vect = CountVectorizer(max_features=100)\n",
    "    tf_matrix = count_vect.fit_transform(text)\n",
    "    feature_names = list(count_vect.vocabulary_.keys())\n",
    "\n",
    "    tf_df = pd.DataFrame(tf_matrix.toarray(), columns=feature_names)\n",
    "    word_counts = tf_df.sum(axis=0)\n",
    "    word_counts_sorted = word_counts.sort_values(ascending=False)\n",
    "\n",
    "    # Die ersten 50 häufigsten Wörter ausgeben\n",
    "    top_words = word_counts_sorted.head(200).to_frame().reset_index()\n",
    "    top_words.columns = ['word', 'count']\n",
    "    top_words.style.format({'count': '{:,}'})\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32b68048-2626-4cf6-b9a9-b6cd557568c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_word_frequencies(df).to_csv(OUTPUT_DIR + \"dataset_word_freq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903beacd-32fb-4765-8a2d-09e8a811a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentiment in [0, 1, 2]:\n",
    "    get_word_frequencies(df[df[\"sentiment\"] == sentiment]).to_csv(OUTPUT_DIR + f'dataset_word_freq_sentiment_{get_sentiment_as_name(sentiment)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0f8b22c-4fb6-4ec2-bf03-1694447e71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentiment in [0, 1, 2]:\n",
    "    for party in PARTIES:\n",
    "        get_word_frequencies(df[(df[\"sentiment\"] == sentiment) & (df[\"source_party\"] == party)].reset_index(drop=True)).reset_index().to_csv(OUTPUT_DIR + f'dataset_word_freq_sentiment_{get_sentiment_as_name(sentiment)}_party_{party}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9049e78-db96-4a82-8c13-14796b2ea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentiment in [0, 1, 2]:\n",
    "    for month in range(1, 13):\n",
    "        get_word_frequencies(df[(df[\"sentiment\"] == sentiment) & (pd.to_datetime(df['date']).dt.month == month)]).to_csv(OUTPUT_DIR + f'dataset_word_freq_sentiment_{get_sentiment_as_name(sentiment)}_month_{get_month_code(month)}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
